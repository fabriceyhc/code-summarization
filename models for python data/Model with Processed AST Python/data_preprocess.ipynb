{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import string, re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "    f = open(filename,  encoding=\"utf8\")\n",
    "    lines = f.readlines()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The directory where the dataset is stored\n",
    "directory = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASTs loaded:  72000\n",
      "Declarations loaded:  72000\n",
      "Descriptions loaded:  72000\n"
     ]
    }
   ],
   "source": [
    "#Read the dataset into following lists:\n",
    "ast_list = load_doc(directory + \"parallel_AST\")\n",
    "\n",
    "decl_list = load_doc(directory + \"updated_parellel_decl\")\n",
    "\n",
    "desc_list = load_doc(directory + \"updated_parellel_desc\")\n",
    "\n",
    "#store all 3 lists in a single list for common processing\n",
    "all_data = [ast_list, decl_list, desc_list]\n",
    "\n",
    "print(\"ASTs loaded: \", len(ast_list))\n",
    "print(\"Declarations loaded: \", len(decl_list))\n",
    "print(\"Descriptions loaded: \", len(desc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(lines):\n",
    "    cleaned = []\n",
    "    for line in lines:\n",
    "        clean = re.sub(r\"\"\"\n",
    "               [,.;@#?!&$()='\\\\_`:>\"%/{}*]+  # Accept one or more copies of punctuation\n",
    "               \\ *           # plus zero or more copies of a space,\n",
    "               \"\"\",\n",
    "               \" \",          # and replace it with a single space\n",
    "               line, flags=re.VERBOSE)\n",
    "        #Manually handle cases not accepted by sub\n",
    "        clean = clean.replace(\"[\", \"\")\n",
    "        clean = clean.replace(\"]\", \"\")\n",
    "        clean = clean.replace(\"-\", \"\")\n",
    "        # tokenize on white space\n",
    "        line = clean.split()\n",
    "        # convert to lower case\n",
    "        line = [word.lower() for word in line]\n",
    "        # store as string\n",
    "        cleaned.append(' '.join(line))\n",
    "    # remove empty strings\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASTs cleaned:  72000\n",
      "Declarations cleaned:  72000\n",
      "Descriptions cleaned:  72000\n"
     ]
    }
   ],
   "source": [
    "clean_ast_list = clean_data(ast_list)\n",
    "clean_decl_list = clean_data(decl_list)\n",
    "clean_desc_list = clean_data(desc_list)\n",
    "\n",
    "print(\"ASTs cleaned: \", len(clean_ast_list))\n",
    "print(\"Declarations cleaned: \", len(clean_decl_list))\n",
    "print(\"Descriptions cleaned: \", len(clean_desc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(body=[FunctionDef(name='_load_file', args=arguments(args=[Name(id='filename', ctx=Param())], vararg=None, kwarg=None, defaults=[]), body=[Assign(targets=[Name(id='fp', ctx=Store())], value=Call(func=Name(id='open', ctx=Load()), args=[Name(id='filename', ctx=Load()), Str(s='rb')], keywords=[], starargs=None, kwargs=None)), Assign(targets=[Name(id='source', ctx=Store())], value=BinOp(left=Call(func=Attribute(value=Name(id='fp', ctx=Load()), attr='read', ctx=Load()), args=[], keywords=[], starargs=None, kwargs=None), op=Add(), right=Str(s='\\n'))), TryExcept(body=[Assign(targets=[Name(id='co', ctx=Store())], value=Call(func=Name(id='compile', ctx=Load()), args=[Name(id='source', ctx=Load()), Name(id='filename', ctx=Load()), Str(s='exec')], keywords=[], starargs=None, kwargs=None))], handlers=[ExceptHandler(type=Name(id='SyntaxError', ctx=Load()), name=None, body=[Print(dest=Attribute(value=Name(id='sys', ctx=Load()), attr='stderr', ctx=Load()), values=[Str(s='>>Syntax \\terror \\tin'), Name(id='filename', ctx=Load())], nl=True), Raise(type=None, inst=None, tback=None)])], orelse=[]), Expr(value=Call(func=Attribute(value=Name(id='fp', ctx=Load()), attr='close', ctx=Load()), args=[], keywords=[], starargs=None, kwargs=None)), Return(value=Name(id='co', ctx=Load()))], decorator_list=[])])\n",
      "\n",
      "module body functiondef name load file args arguments args name id filename ctx param vararg none kwarg none defaults body assign targets name id fp ctx store value call func name id open ctx load args name id filename ctx load str s rb keywords starargs none kwargs none assign targets name id source ctx store value binop left call func attribute value name id fp ctx load attr read ctx load args keywords starargs none kwargs none op add right str s n tryexcept body assign targets name id co ctx store value call func name id compile ctx load args name id source ctx load name id filename ctx load str s exec keywords starargs none kwargs none handlers excepthandler type name id syntaxerror ctx load name none body print dest attribute value name id sys ctx load attr stderr ctx load values str s syntax terror tin name id filename ctx load nl true raise type none inst none tback none orelse expr value call func attribute value name id fp ctx load attr close ctx load args keywords starargs none kwargs none return value name id co ctx load decorator list\n"
     ]
    }
   ],
   "source": [
    "#Comparison of original and processed files\n",
    "print(ast_list[0])\n",
    "print(clean_ast_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write processed data to respective files\n",
    "#Concatenate declaration and AST -> Input\n",
    "#Description -> Output/Label\n",
    "\n",
    "file1 = open(\"input_train.txt\", \"w\", encoding=\"utf8\")\n",
    "file2 = open(\"input_dev.txt\", \"w\", encoding=\"utf8\")\n",
    "file3 = open(\"input_test.txt\", \"w\", encoding=\"utf8\")\n",
    "for index in range(len(clean_ast_list)):\n",
    "    if index < 68000:\n",
    "        file1.write(str(clean_decl_list[index]) + \" \" + str(clean_ast_list[index]) + \"\\n\")\n",
    "    elif index <70000:\n",
    "        file2.write(str(clean_decl_list[index]) + \" \" + str(clean_ast_list[index]) + \"\\n\")\n",
    "    else:\n",
    "        file3.write(str(clean_decl_list[index]) + \" \" + str(clean_ast_list[index]) + \"\\n\")\n",
    "file1.close()\n",
    "file2.close()\n",
    "file3.close()\n",
    "\n",
    "file1 = open(\"summary_train.txt\", \"w\", encoding=\"utf8\")\n",
    "file2 = open(\"summary_dev.txt\", \"w\", encoding=\"utf8\")\n",
    "file3 = open(\"summary_test.txt\", \"w\", encoding=\"utf8\")\n",
    "for index in range(len(clean_desc_list)):\n",
    "    if index < 68000:\n",
    "        file1.write(str(clean_desc_list[index]) + \"\\n\")\n",
    "    elif index <70000:\n",
    "        file2.write(str(clean_desc_list[index]) + \"\\n\")\n",
    "    else:\n",
    "        file3.write(str(clean_desc_list[index]) + \"\\n\")\n",
    "file1.close()\n",
    "file2.close()\n",
    "file3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
