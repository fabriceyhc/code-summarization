{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import string, re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "    f = open(filename,  encoding=\"utf8\")\n",
    "    lines = f.readlines()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The directory where the dataset is stored\n",
    "directory = 'original data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Declarations loaded:  72000\n",
      "Descriptions loaded:  72000\n"
     ]
    }
   ],
   "source": [
    "#Read the dataset into following lists:\n",
    "#ast_list = load_doc(directory + \"parallel_AST\")\n",
    "\n",
    "decl_list = load_doc(directory + \"updated_parellel_decl+bodies\")\n",
    "\n",
    "desc_list = load_doc(directory + \"updated_parellel_desc\")\n",
    "\n",
    "#store all 3 lists in a single list for common processing\n",
    "all_data = [decl_list, desc_list]\n",
    "\n",
    "#print(\"ASTs loaded: \", len(ast_list))\n",
    "print(\"Declarations loaded: \", len(decl_list))\n",
    "print(\"Descriptions loaded: \", len(desc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def clean_data(lines):\n",
    "    cleaned = []\n",
    "    for line in lines:\n",
    "        clean = re.sub(r\"\"\"\n",
    "               [,.;@#?!&$()='\\\\_`:>\"%/{}*]+  # Accept one or more copies of punctuation\n",
    "               \\ *           # plus zero or more copies of a space,\n",
    "               \"\"\",\n",
    "               \" \",          # and replace it with a single space\n",
    "               line, flags=re.VERBOSE)\n",
    "        #Manually handle cases not accepted by sub\n",
    "        clean = clean.replace(\"[\", \"\")\n",
    "        clean = clean.replace(\"]\", \"\")\n",
    "        clean = clean.replace(\"-\", \"\")\n",
    "        # tokenize on white space\n",
    "        line = clean.split()\n",
    "        # convert to lower case\n",
    "        line = [word.lower() for word in line]\n",
    "        # store as string\n",
    "        cleaned.append(' '.join(line))\n",
    "    # remove empty strings\n",
    "    return cleaned\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASTs cleaned:  72000\n",
      "Declarations cleaned:  72000\n",
      "Descriptions cleaned:  72000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"clean_ast_list = clean_data(ast_list)\n",
    "clean_decl_list = clean_data(decl_list)\n",
    "clean_desc_list = clean_data(desc_list)\n",
    "\n",
    "print(\"ASTs cleaned: \", len(clean_ast_list))\n",
    "print(\"Declarations cleaned: \", len(clean_decl_list))\n",
    "print(\"Descriptions cleaned: \", len(clean_desc_list))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def _load_file(filename): DCNL  DCSP fp = open(filename, 'rb') DCNL DCSP source = (fp.read() + '\\n') DCNL DCSP try: DCNL DCSP  DCSP co = compile(source, filename, 'exec') DCNL DCSP except SyntaxError: DCNL DCSP  DCSP print >>sys.stderr, '>>Syntax DCSP error DCSP in', filename DCNL DCSP  DCSP raise DCNL DCSP fp.close() DCNL DCSP return co\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Comparison of original and processed files\n",
    "print(decl_list[0])\n",
    "#print(clean_ast_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write processed data to respective files\n",
    "#Concatenate declaration and AST -> Input\n",
    "#Description -> Output/Label\n",
    "\n",
    "file1 = open(\"input_train.txt\", \"w\", encoding=\"utf8\")\n",
    "file2 = open(\"input_dev.txt\", \"w\", encoding=\"utf8\")\n",
    "file3 = open(\"input_test.txt\", \"w\", encoding=\"utf8\")\n",
    "for index in range(len(decl_list)):\n",
    "    if index < 68000:\n",
    "        file1.write(str(decl_list[index]) + \"\\n\")\n",
    "    elif index <70000:\n",
    "        file2.write(str(decl_list[index]) + \"\\n\")\n",
    "    else:\n",
    "        file3.write(str(decl_list[index]) + \"\\n\")\n",
    "file1.close()\n",
    "file2.close()\n",
    "file3.close()\n",
    "\n",
    "file1 = open(\"summary_train.txt\", \"w\", encoding=\"utf8\")\n",
    "file2 = open(\"summary_dev.txt\", \"w\", encoding=\"utf8\")\n",
    "file3 = open(\"summary_test.txt\", \"w\", encoding=\"utf8\")\n",
    "for index in range(len(desc_list)):\n",
    "    if index < 68000:\n",
    "        file1.write(str(desc_list[index]) + \"\\n\")\n",
    "    elif index <70000:\n",
    "        file2.write(str(desc_list[index]) + \"\\n\")\n",
    "    else:\n",
    "        file3.write(str(desc_list[index]) + \"\\n\")\n",
    "file1.close()\n",
    "file2.close()\n",
    "file3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
